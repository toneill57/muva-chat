# Cost Monitoring System - Plan de ImplementaciÃ³n

**Proyecto:** AI Cost Monitoring & Tracking
**Fecha Inicio:** 2025-10-03
**Estado:** ðŸ“‹ PlanificaciÃ³n â†’ EjecuciÃ³n

---

## ðŸŽ¯ OVERVIEW

### Objetivo Principal
Implementar sistema completo de monitoreo y tracking de costos para APIs de AI (Anthropic Claude + OpenAI), permitiendo visibilidad en tiempo real del gasto, anÃ¡lisis de uso, y alertas proactivas de anomalÃ­as.

### Â¿Por quÃ©?
- **ValidaciÃ³n de costos**: Actualmente no hay forma de verificar el target de $0.33/mes para 100 sesiones
- **Control presupuestario**: Sin monitoring, el gasto puede crecer sin control
- **OptimizaciÃ³n**: Necesitamos datos para identificar oportunidades de ahorro
- **Compliance**: Detectar anomalÃ­as antes de que generen costos significativos (>$10/dÃ­a)

### Alcance
- âœ… Track de compresiones (Claude Haiku): tokens, costo estimado, timestamp
- âœ… Track de embeddings (OpenAI): dimensiones, costo estimado, cache hits/misses
- âœ… Almacenamiento en Supabase: tabla `ai_usage_metrics` con RLS
- âœ… API para consultar mÃ©tricas: `/api/metrics` (agregados diarios/mensuales)
- âœ… Sistema de alertas: Threshold configurable (default: $10/dÃ­a)
- âœ… Dashboard bÃ¡sico (opcional): VisualizaciÃ³n de costos en tiempo real
- âŒ NO incluye: IntegraciÃ³n con Stripe, facturaciÃ³n, billing automÃ¡tico

---

## ðŸ“Š ESTADO ACTUAL

### Sistema Existente
- âœ… Conversation Memory implementado y funcional
- âœ… CompresiÃ³n con Claude Haiku (`conversation-compressor.ts`)
- âœ… Embeddings con OpenAI (`text-embedding-3-large`)
- âœ… Supabase configurado con RLS policies
- âœ… ANTHROPIC_API_KEY y OPENAI_API_KEY configurados

### Limitaciones Actuales
- âŒ No hay tracking de costos de AI APIs
- âŒ No se puede validar el target de $0.33/mes
- âŒ Sin visibilidad de tokens consumidos por dÃ­a/mes
- âŒ Sin alertas de anomalÃ­as (ej: spike de compressions)
- âŒ Sin forma de calcular ROI o cost per session

**Evidencia del problema** (de VALIDATION.md):
```
ISSUE #3: No Production Cost Monitoring
- Missing: Compression count per day/month
- Missing: Embedding API calls (OpenAI usage)
- Missing: Average tokens per compression
- Missing: Cost per session lifecycle
```

---

## ðŸš€ ESTADO DESEADO

### Nueva Experiencia
Sistema de monitoring transparente que permite a desarrolladores y stakeholders:
1. Ver costos en tiempo real (dashboard o API)
2. Recibir alertas proactivas si el gasto excede thresholds
3. Analizar uso histÃ³rico (compressions/dÃ­a, embeddings/dÃ­a)
4. Validar targets de costo ($0.33/mes para 100 sesiones)
5. Identificar oportunidades de optimizaciÃ³n (ej: cache hit rate bajo)

### CaracterÃ­sticas Clave
- **Real-time tracking**: Cada compression/embedding logea mÃ©tricas instantÃ¡neamente
- **Granular metrics**: Tokens input/output, costo estimado, modelo usado, timestamp
- **Aggregation**: ResÃºmenes diarios/mensuales con trends
- **Alerts**: Notificaciones cuando se exceden umbrales ($10/dÃ­a default)
- **Cost breakdown**: Por servicio (Claude vs OpenAI), por sesiÃ³n, por tenant

---

## ðŸ“± TECHNICAL STACK

### Backend
- **TypeScript/Node.js** - LÃ³gica de tracking y cÃ¡lculo de costos
- **Supabase (PostgreSQL)** - Almacenamiento de mÃ©tricas con RLS
- **Next.js API Routes** - Endpoints para consultar mÃ©tricas

### AI APIs (costos a trackear)
- **Anthropic Claude Haiku**: $1/1M input tokens, $5/1M output tokens
- **OpenAI text-embedding-3-large**: $0.13/1M tokens (1024d)

### Monitoring (futuro)
- **Grafana/DataDog (opcional)**: Dashboards avanzados
- **Slack/Email (opcional)**: Alertas automÃ¡ticas

---

## ðŸ”§ DESARROLLO - FASES

### FASE 1: Cost Tracking Core (2h)
**Objetivo:** Implementar sistema base de tracking de costos para AI APIs

**Entregables:**
- `src/lib/cost-tracker.ts` - MÃ³dulo central de tracking con funciones:
  - `trackCompression(tokens, model, sessionId)` â†’ calcula costo y logea
  - `trackEmbedding(tokens, model, sessionId)` â†’ calcula costo y logea
  - `calculateCost(usage, model)` â†’ pricing hardcodeado por modelo
- Modificar `src/lib/conversation-compressor.ts`:
  - Agregar `await trackCompression(...)` despuÃ©s de cada compresiÃ³n exitosa
  - Logear tokens: `response.usage.input_tokens`, `response.usage.output_tokens`
- MigraciÃ³n Supabase: `supabase/migrations/YYYYMMDDHHMMSS_create_ai_usage_metrics.sql`
  - Tabla: `ai_usage_metrics` (id, timestamp, service, model, tokens_in, tokens_out, cost_usd, session_id, tenant_id)
  - RLS policy: Users can view own tenant metrics
  - Indexes: (timestamp, tenant_id), (session_id)

**Archivos a crear:**
- `src/lib/cost-tracker.ts` (nuevo)
- `supabase/migrations/YYYYMMDDHHMMSS_create_ai_usage_metrics.sql` (nuevo)

**Archivos a modificar:**
- `src/lib/conversation-compressor.ts` (agregar tracking despuÃ©s de lÃ­nea 131)

**Testing:**
- Unit test: `src/lib/__tests__/cost-tracker.test.ts`
  - Test pricing calculation (Haiku: 450 input, 180 output â†’ $0.00135)
  - Test database insertion
- Integration test: Comprimir conversaciÃ³n y verificar entry en `ai_usage_metrics`

---

### FASE 2: Embedding Cost Tracking (1.5h)
**Objetivo:** Extender tracking para incluir costos de embeddings (OpenAI)

**Entregables:**
- Modificar `src/lib/conversation-compressor.ts`:
  - FunciÃ³n `generateEmbeddingForSummary()` (lÃ­nea ~239)
  - Agregar `await trackEmbedding(...)` despuÃ©s de generaciÃ³n exitosa
  - Calcular tokens: `summary.length / 4` (aproximaciÃ³n, OpenAI usa ~4 chars/token)
- Modificar `src/lib/conversation-memory-search.ts`:
  - Agregar tracking en bÃºsqueda cuando hay cache MISS (lÃ­nea 62)
  - `await trackEmbedding(...)` despuÃ©s de `generateEmbeddingForSummary()`
- Actualizar `cost-tracker.ts`:
  - Agregar soporte para modelo `text-embedding-3-large` ($0.13/1M tokens)
  - Calcular costo: `(tokens / 1_000_000) * 0.13`

**Archivos a modificar:**
- `src/lib/cost-tracker.ts` (agregar pricing para embeddings)
- `src/lib/conversation-compressor.ts` (lÃ­nea ~245, despuÃ©s de embedding)
- `src/lib/conversation-memory-search.ts` (lÃ­nea ~62, en cache miss)

**Testing:**
- Test: Generar embedding y verificar entry con `service: 'openai'`
- Test: Verificar que cache HIT no genera entry (no cost si cached)
- Test: Calcular costo correcto para 1000 tokens â†’ $0.00013

---

### FASE 3: Metrics API & Aggregation (2h)
**Objetivo:** Crear API para consultar mÃ©tricas agregadas (diarias/mensuales)

**Entregables:**
- `src/app/api/metrics/route.ts` - GET endpoint con query params:
  - `?period=day|week|month` - Periodo de agregaciÃ³n
  - `?service=anthropic|openai|all` - Filtrar por servicio
  - Response: `{ total_cost, breakdown: [...], usage_count }`
- `src/lib/metrics-aggregator.ts` - Funciones de agregaciÃ³n:
  - `getDailyCosts(tenantId, date)` â†’ suma costos del dÃ­a
  - `getMonthlyCosts(tenantId, year, month)` â†’ suma costos del mes
  - `getServiceBreakdown(tenantId, period)` â†’ breakdown por servicio
- Supabase RPC function: `supabase/migrations/YYYYMMDDHHMMSS_create_cost_aggregation_rpc.sql`
  - `get_cost_summary(tenant_id, start_date, end_date)` â†’ retorna agregados

**Archivos a crear:**
- `src/app/api/metrics/route.ts` (nuevo)
- `src/lib/metrics-aggregator.ts` (nuevo)
- `supabase/migrations/YYYYMMDDHHMMSS_create_cost_aggregation_rpc.sql` (nuevo)

**Testing:**
- Test API: `curl /api/metrics?period=day` â†’ retorna JSON vÃ¡lido
- Test: Insertar 10 entries, verificar suma correcta en agregaciÃ³n
- Test: Filtrar por servicio `?service=anthropic` â†’ solo Claude costs

---

### FASE 4: Alerts & Monitoring (1.5h)
**Objetivo:** Sistema de alertas para detectar anomalÃ­as de costo

**Entregables:**
- `src/lib/cost-alerts.ts` - Sistema de alertas:
  - `checkDailyThreshold(tenantId, threshold)` â†’ compara gasto del dÃ­a con threshold
  - `triggerAlert(type, message, cost)` â†’ logea alerta (console por ahora, futuro: Slack/email)
  - Default threshold: $10/dÃ­a
- Modificar `cost-tracker.ts`:
  - DespuÃ©s de cada track, llamar `checkDailyThreshold()`
  - Si excede, trigger alert: `âš ï¸ Daily cost threshold exceeded: $12.50 > $10.00`
- Script de anÃ¡lisis: `scripts/analyze-costs.ts`
  - CLI tool para generar reportes de costos
  - Usage: `npx tsx scripts/analyze-costs.ts --period month`
  - Output: Tabla con breakdown por dÃ­a, servicio, y total
- DocumentaciÃ³n final: `docs/cost-monitoring/fase-4/ALERTS.md`
  - CÃ³mo configurar thresholds
  - CÃ³mo interpretar alertas
  - CÃ³mo integrar con Slack/email (futuro)

**Archivos a crear:**
- `src/lib/cost-alerts.ts` (nuevo)
- `scripts/analyze-costs.ts` (nuevo)
- `docs/cost-monitoring/fase-4/ALERTS.md` (nuevo)

**Archivos a modificar:**
- `src/lib/cost-tracker.ts` (agregar check de threshold despuÃ©s de track)

**Testing:**
- Test: Insertar entries que suman $11 en un dÃ­a â†’ debe trigger alert
- Test: Threshold personalizado ($5/dÃ­a) â†’ alert a $6
- Test: Script de anÃ¡lisis retorna datos correctos para mes completo

---

## âœ… CRITERIOS DE Ã‰XITO

### Funcionalidad
- [ ] Sistema trackea 100% de compresiones con costo exacto
- [ ] Sistema trackea 100% de embeddings (excepto cache hits)
- [ ] API `/api/metrics` retorna datos agregados correctamente
- [ ] Alertas se disparan cuando se excede threshold ($10/dÃ­a)
- [ ] Cache hits NO generan costo (correctamente excluidos)
- [ ] Multi-tenant: Cada tenant ve solo sus costos (RLS funciona)

### Performance
- [ ] Tracking no agrega >5ms de latency a compression
- [ ] Tracking no agrega >2ms de latency a embedding
- [ ] API `/api/metrics` responde en <200ms (agregaciÃ³n eficiente)
- [ ] Database size: <100MB para 1M entries (schema optimizado)

### PrecisiÃ³n de Costos
- [ ] Costo calculado match con pricing real de APIs (Â±5% error)
- [ ] Compression: 450 input + 180 output tokens â†’ $0.00135 (Haiku)
- [ ] Embedding: 1000 tokens â†’ $0.00013 (OpenAI text-embedding-3-large)
- [ ] Total mensual para 100 sesiones: $0.30-$0.45 (validado)

### Calidad de CÃ³digo
- [ ] Tests unitarios: 90%+ coverage en cost-tracker
- [ ] Tests de integraciÃ³n: 100% de flujos crÃ­ticos cubiertos
- [ ] TypeScript: 0 errores, tipos estrictos
- [ ] DocumentaciÃ³n: README en docs/cost-monitoring/ con ejemplos

---

## ðŸ¤– AGENTES REQUERIDOS

### 1. **backend-developer** (Principal)
**Responsabilidad:** ImplementaciÃ³n completa del sistema de cost monitoring

**Tareas:**
- FASE 1: Crear cost-tracker.ts, migraciÃ³n DB, modificar compressor
- FASE 2: Extender tracking a embeddings, actualizar search
- FASE 3: Implementar API de mÃ©tricas, agregaciÃ³n, RPC functions
- FASE 4: Sistema de alertas, script de anÃ¡lisis, documentaciÃ³n

**Archivos:**
- `src/lib/cost-tracker.ts` (crear)
- `src/lib/conversation-compressor.ts` (modificar)
- `src/lib/conversation-memory-search.ts` (modificar)
- `src/lib/metrics-aggregator.ts` (crear)
- `src/lib/cost-alerts.ts` (crear)
- `src/app/api/metrics/route.ts` (crear)
- `supabase/migrations/*.sql` (crear 2 migraciones)
- `scripts/analyze-costs.ts` (crear)

### 2. **database-agent** (Soporte)
**Responsabilidad:** Validar schema, RLS policies, y performance de queries

**Tareas:**
- FASE 1: Review migraciÃ³n `ai_usage_metrics`, validar indexes
- FASE 3: Review RPC function `get_cost_summary`, optimizar query
- FASE 4: Validar que queries de aggregation usan indexes correctamente

**Archivos:**
- `supabase/migrations/*.sql` (review)

---

## ðŸ“‚ ESTRUCTURA DE ARCHIVOS

```
/Users/oneill/Sites/apps/InnPilot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ cost-tracker.ts              # [CREAR] Sistema central tracking
â”‚   â”‚   â”œâ”€â”€ metrics-aggregator.ts        # [CREAR] AgregaciÃ³n de mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ cost-alerts.ts               # [CREAR] Sistema de alertas
â”‚   â”‚   â”œâ”€â”€ conversation-compressor.ts   # [MODIFICAR] Agregar tracking
â”‚   â”‚   â””â”€â”€ conversation-memory-search.ts # [MODIFICAR] Track embeddings
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â””â”€â”€ metrics/
â”‚   â”‚           â””â”€â”€ route.ts             # [CREAR] API endpoint
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ __tests__/
â”‚           â”œâ”€â”€ cost-tracker.test.ts     # [CREAR] Unit tests
â”‚           â””â”€â”€ metrics-aggregator.test.ts # [CREAR] Tests agregaciÃ³n
â”œâ”€â”€ supabase/
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ YYYYMMDDHHMMSS_create_ai_usage_metrics.sql  # [CREAR]
â”‚       â””â”€â”€ YYYYMMDDHHMMSS_create_cost_aggregation_rpc.sql # [CREAR]
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ analyze-costs.ts                 # [CREAR] CLI tool anÃ¡lisis
â””â”€â”€ docs/
    â””â”€â”€ cost-monitoring/
        â”œâ”€â”€ fase-1/
        â”‚   â”œâ”€â”€ IMPLEMENTATION.md
        â”‚   â”œâ”€â”€ CHANGES.md
        â”‚   â””â”€â”€ TESTS.md
        â”œâ”€â”€ fase-2/
        â”‚   â””â”€â”€ ...
        â”œâ”€â”€ fase-3/
        â”‚   â””â”€â”€ ...
        â”œâ”€â”€ fase-4/
        â”‚   â”œâ”€â”€ ALERTS.md
        â”‚   â””â”€â”€ USAGE.md
        â””â”€â”€ README.md                    # GuÃ­a completa del sistema
```

---

## ðŸ“ NOTAS IMPORTANTES

### Consideraciones TÃ©cnicas

**Pricing Hardcoded (Oct 2025)**
- Claude Haiku 3.5: $1/1M input, $5/1M output
- OpenAI text-embedding-3-large: $0.13/1M tokens
- **IMPORTANTE**: Pricing puede cambiar. Documentar en README cÃ³mo actualizar.

**AproximaciÃ³n de Tokens (Embeddings)**
- OpenAI no retorna token count en response
- Usamos aproximaciÃ³n: `summary.length / 4` (1 token â‰ˆ 4 chars en espaÃ±ol)
- PrecisiÃ³n: Â±10% (aceptable para estimaciÃ³n de costos)

**RLS Policies**
- `ai_usage_metrics` debe tener RLS para multi-tenant isolation
- Policy: `tenant_id = current_setting('app.current_tenant')`
- Admin puede ver todos (service role bypasses RLS)

**Performance**
- Tracking es async, no bloquea response al usuario
- Usar `Promise.allSettled()` para evitar crashes si DB falla
- Logging de errores: `console.error('[cost-tracker] Failed to log:', error)`

**Cache Hits (OpenAI)**
- Cache hits NO deben generar cost entry (embedding ya existe)
- Solo trackear en `embeddingCache.get()` returns `null` (cache miss)
- Verificar: `conversation-memory-search.ts` lÃ­nea 60-66

**Alert Fatigue**
- Evitar alertas repetidas (max 1 alerta por hora por threshold)
- Implementar debouncing: `lastAlertTimestamp` en memoria/DB
- Futuro: Configurar diferentes thresholds por tenant

**Migration Strategy**
- Backfill histÃ³rico NO es necesario (empezar tracking desde deploy)
- Si hay datos legacy: Crear script de estimaciÃ³n basado en `conversation_memory.message_count`

---

**Ãšltima actualizaciÃ³n:** 2025-10-03
**PrÃ³ximo paso:** Actualizar TODO.md con tareas especÃ­ficas por fase
