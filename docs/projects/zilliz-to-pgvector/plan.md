# Zilliz ‚Üí Supabase pgvector Migration - Plan de Implementaci√≥n

**Proyecto:** Vector Database Migration
**Fecha Inicio:** 9 Octubre 2025
**Estado:** üìã Planificaci√≥n

---

## üéØ OVERVIEW

### Objetivo Principal

Migrar el semantic code search del MCP server `claude-context` de **Zilliz Cloud** (Milvus serverless) a **Supabase pgvector**, consolidando toda la infraestructura vectorial en PostgreSQL y eliminando dependencias externas.

### ¬øPor qu√©?

**Consolidaci√≥n de Infraestructura:**
- **Infraestructura unificada**: Todo en Supabase PostgreSQL (database + vectors)
- **Reducci√≥n de costos**: Eliminar subscription de Zilliz Cloud (~$20-50/mes)
- **Menor latencia**: Sin llamadas de red externa, todo dentro de Supabase
- **Mejor integraci√≥n**: Mismo stack que embeddings de premium chat (ya usa pgvector)

**Ventajas T√©cnicas:**
- **pgvector 0.8.0 ya instalado**: Extension disponible y configurada
- **Performance comparable**: pgvector 0.8.0 tiene HNSW index (similar a Milvus)
- **Mejor debugging**: Queries SQL est√°ndar vs Milvus API
- **RLS nativo**: Row Level Security para multi-tenant si necesario en futuro

**Mantenibilidad:**
- **Un solo sistema**: PostgreSQL para todo (data + vectors)
- **Backups unificados**: Supabase gestiona todo
- **Menos complejidad**: Eliminar configuraci√≥n de Zilliz Cloud

### Alcance

**INCLUYE:**
- ‚úÖ Schema pgvector en Supabase para code embeddings
- ‚úÖ Migraci√≥n de embeddings existentes de Zilliz ‚Üí pgvector
- ‚úÖ Actualizaci√≥n de configuraci√≥n MCP claude-context
- ‚úÖ Testing de semantic search (comparaci√≥n performance)
- ‚úÖ Documentaci√≥n completa del proceso

**NO INCLUYE:**
- ‚ùå Re-indexar codebase (usamos embeddings existentes)
- ‚ùå Cambiar modelo de embeddings (mantenemos OpenAI text-embedding-3-small)
- ‚ùå Modificar premium chat embeddings (ya usa pgvector)

---

## üìä ESTADO ACTUAL

### Sistema Existente

**Zilliz Cloud (claude-context MCP):**
- ‚úÖ 818 archivos indexados del codebase
- ‚úÖ 33,257 chunks de c√≥digo con embeddings
- ‚úÖ OpenAI text-embedding-3-small (1536 dimensions)
- ‚úÖ Semantic search funcionando (< 2s respuesta)
- ‚úÖ 90.4% token reduction medido (FASE 6 MCP Optimization)

**Supabase PostgreSQL:**
- ‚úÖ pgvector 0.8.0 instalado y funcional
- ‚úÖ Ya usado para premium chat embeddings (tabla: `conversation_embeddings`)
- ‚úÖ HNSW index disponible (similar performance a Milvus)
- ‚úÖ PostgreSQL 17.4.1.075

**MCP Configuration:**
- ‚úÖ `~/.claude/mcp.json` configurado para Zilliz
- ‚úÖ `claude-context` MCP server activo
- ‚úÖ Storage local: `~/.context/merkle/` (indexing state)

### Limitaciones Actuales

**Zilliz Cloud:**
1. **Dependencia Externa**: Requiere red externa para queries (latencia adicional)
2. **Costo Recurrente**: Subscription mensual (~$20-50/mes)
3. **Infraestructura Fragmentada**: Vectores separados de data relacional
4. **Debugging Limitado**: API propietaria vs SQL est√°ndar
5. **Backups Separados**: No incluido en backups de Supabase

**MCP claude-context:**
1. **Configuraci√≥n Hardcoded**: URI de Zilliz en config MCP
2. **Sin Fallback**: Si Zilliz falla, semantic search no funciona
3. **No Multi-tenant Ready**: Sin aislamiento por tenant (no necesario ahora, pero limitante futuro)

---

## üöÄ ESTADO DESEADO

### Nueva Experiencia

**Para Desarrolladores (Claude Code):**
- Semantic search id√©ntico o mejor performance (< 2s)
- Zero cambio en experiencia de usuario (transparente)
- Mejor confiabilidad (sin dependencia de servicio externo)

**Para el Sistema:**
- Todo en Supabase PostgreSQL (data + vectors)
- Queries SQL est√°ndar para debugging
- Backups unificados autom√°ticos
- Infraestructura simplificada (un solo sistema)

### Caracter√≠sticas Clave

1. **Schema pgvector Optimizado**:
   - Tabla `code_embeddings` con columnas: `id`, `file_path`, `chunk_index`, `content`, `embedding` (vector(1536)), `metadata` (jsonb)
   - HNSW index para b√∫squedas r√°pidas
   - √çndices en `file_path` para filtros

2. **Migraci√≥n Sin Downtime**:
   - Exportar embeddings de Zilliz
   - Importar a pgvector
   - Validar integridad (count, sample queries)
   - Actualizar MCP config
   - Testing en paralelo antes de switch

3. **Performance Garantizado**:
   - HNSW index (pgvector 0.8.0) ~ mismo performance que Milvus
   - Target: < 2 segundos para semantic search
   - Medici√≥n antes/despu√©s

4. **Configuraci√≥n MCP Actualizada**:
   - Cambiar URI de Zilliz ‚Üí Supabase en `~/.claude/mcp.json`
   - Mantener misma interfaz de MCP tools
   - Zero cambio en workflow de desarrollo

---

## üì± TECHNICAL STACK

### Database
- **PostgreSQL**: 17.4.1.075 (Supabase)
- **Extension**: pgvector 0.8.0
- **Index Type**: HNSW (Hierarchical Navigable Small World)
- **Vector Dimensions**: 1536 (OpenAI text-embedding-3-small)

### Embeddings
- **Provider**: OpenAI text-embedding-3-small (NO CAMBIA)
- **Dimensions**: 1536 (NO CAMBIA)
- **Source**: Embeddings existentes de Zilliz (NO re-indexar)

### MCP Server
- **Server**: claude-context (NO CAMBIA)
- **Tools**: `index_codebase`, `search_code`, `get_indexing_status` (NO CAMBIAN)
- **Config**: `~/.claude/mcp.json` (ACTUALIZAR URI)

### Migration Tools
- **Export**: Zilliz Cloud API (Python SDK)
- **Import**: Supabase SQL + pgvector
- **Validation**: SQL queries + MCP search tests

---

## üîß DESARROLLO - FASES

### FASE 1: Schema Setup en Supabase pgvector (1h)

**Objetivo:** Crear schema optimizado en PostgreSQL con pgvector para code embeddings

**Agente:** **@agent-database-agent**

**Entregables:**
1. Migraci√≥n SQL con tabla `code_embeddings`
2. HNSW index para b√∫squedas vectoriales
3. √çndices adicionales para filtros (file_path, metadata)
4. Validaci√≥n de schema aplicado

**Archivos a crear:**
- `supabase/migrations/20251009120000_create_code_embeddings_table.sql` (NUEVO)

**Schema SQL:**
```sql
-- Tabla para code embeddings (semantic search)
CREATE TABLE IF NOT EXISTS public.code_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  file_path TEXT NOT NULL,
  chunk_index INTEGER NOT NULL,
  content TEXT NOT NULL,
  embedding vector(1536) NOT NULL,
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- √çndice HNSW para b√∫squedas vectoriales r√°pidas
CREATE INDEX code_embeddings_embedding_idx
  ON code_embeddings
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

-- √çndice para filtros por archivo
CREATE INDEX code_embeddings_file_path_idx
  ON code_embeddings(file_path);

-- √çndice compuesto para b√∫squedas por archivo + chunk
CREATE UNIQUE INDEX code_embeddings_file_chunk_idx
  ON code_embeddings(file_path, chunk_index);

-- Comentarios
COMMENT ON TABLE code_embeddings IS
  'Stores code embeddings for semantic search via claude-context MCP server. Migrated from Zilliz Cloud Oct 2025.';

COMMENT ON COLUMN code_embeddings.embedding IS
  'OpenAI text-embedding-3-small vector (1536 dimensions)';

COMMENT ON COLUMN code_embeddings.metadata IS
  'Additional metadata (language, LOC, last_modified, etc.)';
```

**Testing:**
- Verificar que migraci√≥n aplica sin errores
- Verificar que HNSW index se crea correctamente
- Verificar que tabla est√° vac√≠a (0 rows inicialmente)
- Test de inserci√≥n b√°sica (1 embedding de prueba)
- Verificar que b√∫squeda vectorial funciona (cosine similarity)

**Criterio de √©xito:** Schema creado, √≠ndices funcionales, test de inserci√≥n/b√∫squeda passing

---

### FASE 2: Export de Embeddings desde Zilliz (1h)

**Objetivo:** Exportar todos los embeddings existentes de Zilliz Cloud a formato compatible con pgvector

**Agente:** **@agent-database-agent**

**Entregables:**
1. Script Python para export de Zilliz
2. Archivo JSONL con embeddings exportados
3. Validaci√≥n de integridad (count total, sample checks)
4. Documentaci√≥n del formato de export

**Archivos a crear:**
- `scripts/export-zilliz-embeddings.py` (NUEVO)
- `scripts/validate-zilliz-export.py` (NUEVO)
- `data/code-embeddings-export.jsonl` (NUEVO - gitignored)

**Script de Export:**
```python
# scripts/export-zilliz-embeddings.py
from pymilvus import connections, Collection
import json
import os
from datetime import datetime

# Conectar a Zilliz Cloud
ZILLIZ_URI = os.getenv("ZILLIZ_CLOUD_URI")  # De ~/.claude/mcp.json
ZILLIZ_TOKEN = os.getenv("ZILLIZ_CLOUD_TOKEN")

connections.connect(
    alias="default",
    uri=ZILLIZ_URI,
    token=ZILLIZ_TOKEN
)

# Obtener collection
collection_name = "code_embeddings"  # Nombre usado por claude-context
collection = Collection(collection_name)
collection.load()

# Export todos los embeddings
results = collection.query(
    expr="",  # Sin filtro (todos)
    output_fields=["file_path", "chunk_index", "content", "embedding", "metadata"]
)

# Escribir a JSONL
output_file = "data/code-embeddings-export.jsonl"
os.makedirs("data", exist_ok=True)

with open(output_file, "w") as f:
    for row in results:
        f.write(json.dumps(row) + "\n")

print(f"‚úÖ Exported {len(results)} embeddings to {output_file}")
print(f"Total size: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB")
```

**Validaci√≥n:**
```python
# scripts/validate-zilliz-export.py
import json

with open("data/code-embeddings-export.jsonl") as f:
    lines = f.readlines()

print(f"Total embeddings: {len(lines)}")
print(f"Expected: 33,257 (from MCP indexing)")

# Sample check
sample = json.loads(lines[0])
print(f"Sample keys: {sample.keys()}")
print(f"Embedding dimension: {len(sample['embedding'])}")
print(f"Expected dimension: 1536")

# Validar que todos tienen embedding correcto
for i, line in enumerate(lines):
    row = json.loads(line)
    if len(row['embedding']) != 1536:
        print(f"‚ùå Row {i} has wrong dimension: {len(row['embedding'])}")
        break
else:
    print("‚úÖ All embeddings have correct dimension (1536)")
```

**Testing:**
- Ejecutar script de export
- Verificar que archivo JSONL se crea
- Verificar count total = 33,257 embeddings
- Verificar sample tiene campos correctos
- Ejecutar script de validaci√≥n

**Criterio de √©xito:** 33,257 embeddings exportados, dimensi√≥n 1536 verificada, 0 errores

---

### FASE 3: Import de Embeddings a pgvector (1.5h)

**Objetivo:** Importar embeddings exportados a Supabase pgvector con validaci√≥n de integridad

**Agente:** **@agent-database-agent**

**Entregables:**
1. Script de import optimizado (batch inserts)
2. Validaci√≥n de integridad post-import
3. Performance benchmark de b√∫squedas
4. Documentaci√≥n de proceso

**Archivos a crear:**
- `scripts/import-pgvector-embeddings.ts` (NUEVO)
- `scripts/validate-pgvector-import.sql` (NUEVO)
- `scripts/benchmark-pgvector-search.ts` (NUEVO)

**Script de Import:**
```typescript
// scripts/import-pgvector-embeddings.ts
import { createClient } from '@supabase/supabase-js';
import fs from 'fs';
import readline from 'readline';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

async function importEmbeddings() {
  const fileStream = fs.createReadStream('data/code-embeddings-export.jsonl');
  const rl = readline.createInterface({
    input: fileStream,
    crlfDelay: Infinity
  });

  let batch: any[] = [];
  const BATCH_SIZE = 500;
  let total = 0;

  for await (const line of rl) {
    const row = JSON.parse(line);

    batch.push({
      file_path: row.file_path,
      chunk_index: row.chunk_index,
      content: row.content,
      embedding: row.embedding,
      metadata: row.metadata
    });

    if (batch.length >= BATCH_SIZE) {
      const { error } = await supabase
        .from('code_embeddings')
        .insert(batch);

      if (error) throw error;

      total += batch.length;
      console.log(`‚úÖ Imported ${total} embeddings...`);
      batch = [];
    }
  }

  // Insert remaining
  if (batch.length > 0) {
    const { error } = await supabase
      .from('code_embeddings')
      .insert(batch);

    if (error) throw error;
    total += batch.length;
  }

  console.log(`üéâ Total imported: ${total} embeddings`);
}

importEmbeddings();
```

**Validaci√≥n SQL:**
```sql
-- scripts/validate-pgvector-import.sql

-- 1. Verificar count total
SELECT COUNT(*) as total_embeddings FROM code_embeddings;
-- Expected: 33,257

-- 2. Verificar dimensi√≥n de embeddings
SELECT
  COUNT(*) as total,
  COUNT(*) FILTER (WHERE array_length(embedding::float[], 1) = 1536) as correct_dimension
FROM code_embeddings;
-- Expected: total = 33,257, correct_dimension = 33,257

-- 3. Verificar archivos √∫nicos
SELECT COUNT(DISTINCT file_path) as unique_files FROM code_embeddings;
-- Expected: 818 (archivos indexados)

-- 4. Sample de embeddings
SELECT
  file_path,
  chunk_index,
  LEFT(content, 100) as content_preview,
  array_length(embedding::float[], 1) as embedding_dim
FROM code_embeddings
LIMIT 5;

-- 5. Verificar metadata
SELECT
  metadata->>'language' as language,
  COUNT(*) as count
FROM code_embeddings
GROUP BY language
ORDER BY count DESC;
```

**Benchmark de B√∫squeda:**
```typescript
// scripts/benchmark-pgvector-search.ts
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function benchmarkSearch(query: string) {
  // 1. Generate embedding for query
  const embeddingResponse = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: query
  });
  const queryEmbedding = embeddingResponse.data[0].embedding;

  // 2. Search with pgvector
  const start = performance.now();

  const { data, error } = await supabase.rpc('search_code_embeddings', {
    query_embedding: queryEmbedding,
    match_threshold: 0.7,
    match_count: 10
  });

  const duration = performance.now() - start;

  if (error) throw error;

  console.log(`Query: "${query}"`);
  console.log(`Results: ${data.length}`);
  console.log(`Duration: ${duration.toFixed(0)}ms`);
  console.log(`Target: < 2000ms`);
  console.log(data[0]); // Sample result

  return duration;
}

// Test queries
const queries = [
  "SIRE compliance validation",
  "matryoshka embeddings implementation",
  "guest authentication logic"
];

async function runBenchmarks() {
  const durations: number[] = [];

  for (const query of queries) {
    const duration = await benchmarkSearch(query);
    durations.push(duration);
    console.log('---');
  }

  const avgDuration = durations.reduce((a, b) => a + b) / durations.length;
  console.log(`\nüìä Average duration: ${avgDuration.toFixed(0)}ms`);
  console.log(avgDuration < 2000 ? '‚úÖ PASS' : '‚ùå FAIL');
}

runBenchmarks();
```

**RPC Function para B√∫squeda:**
```sql
-- Crear funci√≥n RPC para semantic search
CREATE OR REPLACE FUNCTION search_code_embeddings(
  query_embedding vector(1536),
  match_threshold float DEFAULT 0.7,
  match_count int DEFAULT 10
)
RETURNS TABLE (
  file_path TEXT,
  chunk_index INTEGER,
  content TEXT,
  similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    ce.file_path,
    ce.chunk_index,
    ce.content,
    1 - (ce.embedding <=> query_embedding) AS similarity
  FROM code_embeddings ce
  WHERE 1 - (ce.embedding <=> query_embedding) > match_threshold
  ORDER BY ce.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

**Testing:**
- Ejecutar script de import (batch de 500)
- Ejecutar validaci√≥n SQL (5 queries)
- Verificar count = 33,257
- Verificar dimensi√≥n = 1536 en todos
- Ejecutar benchmark de b√∫squeda (3 queries)
- Verificar average duration < 2000ms

**Criterio de √©xito:** 33,257 embeddings importados, 0 errores, b√∫squedas < 2s

---

### FASE 4: Actualizaci√≥n de MCP Configuration (30 min)

**Objetivo:** Actualizar configuraci√≥n de claude-context MCP para usar Supabase pgvector

**Agente:** **@agent-infrastructure-monitor**

**Entregables:**
1. Backup de configuraci√≥n actual
2. Configuraci√≥n MCP actualizada
3. Validaci√≥n de conexi√≥n
4. Testing de MCP tools

**Archivos a modificar:**
- `~/.claude/mcp.json` (MODIFICAR - backup primero)

**Configuraci√≥n Actual (Zilliz):**
```json
{
  "mcpServers": {
    "claude-context": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-context"],
      "env": {
        "ZILLIZ_CLOUD_URI": "https://...",
        "ZILLIZ_CLOUD_TOKEN": "..."
      }
    }
  }
}
```

**Configuraci√≥n Nueva (pgvector):**
```json
{
  "mcpServers": {
    "claude-context": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-context"],
      "env": {
        "VECTOR_DB_TYPE": "pgvector",
        "PGVECTOR_CONNECTION_STRING": "postgresql://postgres.[PROJECT_ID]:[PASSWORD]@aws-0-us-west-1.pooler.supabase.com:6543/postgres",
        "OPENAI_API_KEY": "..."
      }
    }
  }
}
```

**Testing:**
- Crear backup de `~/.claude/mcp.json` ‚Üí `~/.claude/mcp.json.backup.zilliz`
- Actualizar configuraci√≥n con credenciales de Supabase
- Reiniciar Claude Code (Cmd+Q ‚Üí reabrir)
- Ejecutar `/mcp` ‚Üí Verificar 5/5 servers conectados
- Test MCP tool: `mcp__claude-context__search_code` con query simple

**Criterio de √©xito:** MCP conectado a pgvector, b√∫squedas funcionando

---

### FASE 5: Testing & Validation (1h)

**Objetivo:** Validar que semantic search funciona id√©ntico o mejor que con Zilliz

**Agente:** **@agent-infrastructure-monitor**

**Entregables:**
1. Comparaci√≥n performance Zilliz vs pgvector
2. Testing de 5 queries reales del proyecto
3. Validaci√≥n de resultados (mismos archivos encontrados)
4. Documentaci√≥n de findings

**Archivos a crear:**
- `docs/projects/zilliz-to-pgvector/PERFORMANCE_COMPARISON.md` (NUEVO)
- `scripts/compare-search-results.ts` (NUEVO)

**Queries de Testing (Mismas de FASE 6 MCP Optimization):**

**Query 1: "SIRE compliance logic"**
- Zilliz: {archivos encontrados, tiempo}
- pgvector: {archivos encontrados, tiempo}
- Comparaci√≥n: ¬øMismos archivos? ¬øMejor/peor tiempo?

**Query 2: "matryoshka embeddings implementation"**
- Zilliz: {archivos encontrados, tiempo}
- pgvector: {archivos encontrados, tiempo}
- Comparaci√≥n: ¬øMismos archivos? ¬øMejor/peor tiempo?

**Query 3: "guest authentication flow"**
- Zilliz: {archivos encontrados, tiempo}
- pgvector: {archivos encontrados, tiempo}
- Comparaci√≥n: ¬øMismos archivos? ¬øMejor/peor tiempo?

**Query 4: "premium chat architecture"**
- Zilliz: {archivos encontrados, tiempo}
- pgvector: {archivos encontrados, tiempo}
- Comparaci√≥n: ¬øMismos archivos? ¬øMejor/peor tiempo?

**Query 5: "database RLS policies"**
- Zilliz: {archivos encontrados, tiempo}
- pgvector: {archivos encontrados, tiempo}
- Comparaci√≥n: ¬øMismos archivos? ¬øMejor/peor tiempo?

**M√©tricas a Medir:**
- **Latencia promedio** (target: < 2000ms)
- **Recall accuracy** (¬øencuentra los mismos archivos relevantes?)
- **Resultado ranking** (¬øorden de resultados similar?)

**Testing:**
- Ejecutar 5 queries con Zilliz (antes de switch) - REGISTRAR RESULTADOS
- Switch a pgvector
- Ejecutar mismas 5 queries con pgvector - REGISTRAR RESULTADOS
- Comparar resultados (tabla comparativa)
- Documentar en PERFORMANCE_COMPARISON.md

**Criterio de √©xito:**
- pgvector latencia ‚â§ Zilliz latencia (o max +20%)
- pgvector encuentra >= 80% de archivos que Zilliz
- 0 errores en b√∫squedas

---

### FASE 6: Cleanup & Documentation (30 min)

**Objetivo:** Limpiar recursos de Zilliz y documentar migraci√≥n completa

**Agente:** **@agent-database-agent**

**Entregables:**
1. Cancelaci√≥n de subscription Zilliz Cloud
2. Backup final de datos Zilliz (por si acaso)
3. Documentaci√≥n completa de migraci√≥n
4. Update de CLAUDE.md y snapshots

**Archivos a crear/modificar:**
- `docs/projects/zilliz-to-pgvector/MIGRATION_GUIDE.md` (NUEVO)
- `CLAUDE.md` (MODIFICAR - actualizar secci√≥n MCP)
- `snapshots/database-agent.md` (MODIFICAR - agregar pgvector info)
- `snapshots/infrastructure-monitor.md` (MODIFICAR - remover Zilliz)

**Tareas de Cleanup:**
1. **Backup final de Zilliz**:
   - Verificar que export JSONL est√° completo
   - Crear backup adicional por seguridad
   - Guardar en `data/backups/zilliz-final-backup-{date}.jsonl`

2. **Cancelar Zilliz subscription**:
   - Login a Zilliz Cloud console
   - Pausar/cancelar proyecto
   - Exportar cualquier metadata adicional
   - Screenshot de confirmaci√≥n

3. **Limpiar configuraci√≥n local**:
   - Remover `~/.claude/mcp.json.backup.zilliz` despu√©s de validar
   - Remover variables de entorno Zilliz de `.env.local` si existen
   - Limpiar `~/.context/merkle/` si tiene referencias Zilliz

**Documentaci√≥n a Crear:**

**MIGRATION_GUIDE.md:**
```markdown
# Zilliz ‚Üí pgvector Migration Guide

**Date:** October 9, 2025
**Status:** ‚úÖ Complete

## Summary
Successfully migrated 33,257 code embeddings from Zilliz Cloud to Supabase pgvector.

## Performance Comparison
- Zilliz average latency: Xms
- pgvector average latency: Yms
- Improvement: Z% (or degradation if slower)

## Steps Executed
1. Schema setup (FASE 1)
2. Export from Zilliz (FASE 2)
3. Import to pgvector (FASE 3)
4. MCP config update (FASE 4)
5. Validation (FASE 5)

## Rollback Plan (if needed)
1. Revert ~/.claude/mcp.json to backup
2. Restart Claude Code
3. Zilliz data still available for 30 days
```

**CLAUDE.md Update:**
```markdown
## üöÄ MCP SERVERS CONFIGURADOS (Oct 2025)

**Stack de Optimizaci√≥n de Tokens:**

1. **claude-context** (Semantic Code Search)
   - ~~Indexaci√≥n: Zilliz Cloud + OpenAI embeddings~~ (DEPRECATED Oct 9, 2025)
   - **Indexaci√≥n: Supabase pgvector + OpenAI embeddings** (MIGRATED Oct 9, 2025)
   - Storage: PostgreSQL table `code_embeddings` (33,257 chunks)
   - Reducci√≥n: ~90.4% tokens en code queries (medido)
   - Tools: index_codebase, search_code, get_indexing_status
   - Performance: < 2s semantic search

**Migration History:**
- Oct 8, 2025: Zilliz Cloud (Milvus serverless)
- Oct 9, 2025: Migrated to Supabase pgvector 0.8.0 (HNSW index)
- Reason: Infrastructure consolidation + cost reduction
```

**Testing:**
- Verificar que documentaci√≥n est√° completa
- Verificar que CLAUDE.md menciona pgvector
- Verificar que backup Zilliz existe
- Verificar que subscription cancelada (screenshot)

**Criterio de √©xito:** Documentaci√≥n completa, Zilliz cancelado, 0 referencias a Zilliz en config

---

## ‚úÖ CRITERIOS DE √âXITO

### Funcionalidad
- [ ] Schema pgvector creado con HNSW index
- [ ] 33,257 embeddings migrados exitosamente
- [ ] Dimensi√≥n 1536 verificada en todos los embeddings
- [ ] MCP claude-context conectado a pgvector
- [ ] Semantic search funcionando (5/5 queries passing)
- [ ] RPC function `search_code_embeddings()` funcional

### Performance
- [ ] B√∫squedas < 2000ms promedio (target)
- [ ] pgvector latencia ‚â§ Zilliz latencia + 20%
- [ ] HNSW index creado correctamente
- [ ] Recall accuracy >= 80% vs Zilliz

### Data Integrity
- [ ] Count total = 33,257 embeddings (100% migrados)
- [ ] 0 embeddings con dimensi√≥n incorrecta
- [ ] 818 archivos √∫nicos representados
- [ ] Metadata preservada en JSONB

### Infrastructure
- [ ] Zilliz Cloud subscription cancelada
- [ ] Backup final de Zilliz creado
- [ ] MCP config actualizado y funcionando
- [ ] Documentaci√≥n completa creada

### Documentation
- [ ] MIGRATION_GUIDE.md creado
- [ ] PERFORMANCE_COMPARISON.md con benchmarks
- [ ] CLAUDE.md actualizado (menci√≥n de pgvector)
- [ ] Snapshots actualizados (database-agent, infrastructure-monitor)

---

## ü§ñ AGENTES REQUERIDOS

### 1. **@agent-database-agent** (Principal)

**Responsabilidad:** Schema, migrations, export/import de embeddings, validaci√≥n SQL

**Tareas:**
- **FASE 1**: Crear schema pgvector con HNSW index
- **FASE 2**: Script de export de Zilliz + validaci√≥n
- **FASE 3**: Script de import a pgvector + benchmark
- **FASE 6**: Cleanup Zilliz, documentaci√≥n t√©cnica

**Archivos:**
- `supabase/migrations/20251009120000_create_code_embeddings_table.sql`
- `scripts/export-zilliz-embeddings.py`
- `scripts/import-pgvector-embeddings.ts`
- `scripts/validate-pgvector-import.sql`
- `scripts/benchmark-pgvector-search.ts`
- `docs/projects/zilliz-to-pgvector/MIGRATION_GUIDE.md`

**Workflow de Revisi√≥n Post-Implementaci√≥n:**
1. Validar que schema pgvector est√° optimizado (HNSW index)
2. Verificar que migraci√≥n de datos fue 100% exitosa
3. Revisar performance de b√∫squedas vectoriales
4. Proponer optimizaciones adicionales (√≠ndices, queries)
5. Documentar findings en `docs/projects/zilliz-to-pgvector/fase-{N}/AGENT_REVIEW.md`

---

### 2. **@agent-infrastructure-monitor** (Secundario)

**Responsabilidad:** MCP configuration, testing de semantic search, performance benchmarks

**Tareas:**
- **FASE 4**: Actualizar MCP config, testing de conexi√≥n
- **FASE 5**: Comparaci√≥n performance Zilliz vs pgvector, validaci√≥n de resultados

**Archivos:**
- `~/.claude/mcp.json` (actualizar config)
- `docs/projects/zilliz-to-pgvector/PERFORMANCE_COMPARISON.md`
- `scripts/compare-search-results.ts`
- `snapshots/infrastructure-monitor.md` (actualizar)

**Workflow de Revisi√≥n Post-Implementaci√≥n:**
1. Validar que MCP claude-context conecta correctamente
2. Verificar performance de semantic search (< 2s)
3. Comparar resultados Zilliz vs pgvector (recall accuracy)
4. Proponer mejoras en configuraci√≥n MCP
5. Documentar findings en `docs/projects/zilliz-to-pgvector/fase-{N}/AGENT_REVIEW.md`

---

## üìÇ ESTRUCTURA DE ARCHIVOS

```
/Users/oneill/Sites/apps/MUVA/
‚îú‚îÄ‚îÄ supabase/migrations/
‚îÇ   ‚îî‚îÄ‚îÄ 20251009120000_create_code_embeddings_table.sql (NUEVO)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ export-zilliz-embeddings.py (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ validate-zilliz-export.py (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ import-pgvector-embeddings.ts (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ validate-pgvector-import.sql (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ benchmark-pgvector-search.ts (NUEVO)
‚îÇ   ‚îî‚îÄ‚îÄ compare-search-results.ts (NUEVO)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ code-embeddings-export.jsonl (NUEVO - gitignored)
‚îÇ   ‚îî‚îÄ‚îÄ backups/
‚îÇ       ‚îî‚îÄ‚îÄ zilliz-final-backup-{date}.jsonl (NUEVO - gitignored)
‚îú‚îÄ‚îÄ docs/projects/zilliz-to-pgvector/
‚îÇ   ‚îú‚îÄ‚îÄ plan.md (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ TODO.md (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ zilliz-to-pgvector-prompt-workflow.md (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ MIGRATION_GUIDE.md (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ PERFORMANCE_COMPARISON.md (NUEVO)
‚îÇ   ‚îú‚îÄ‚îÄ fase-1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IMPLEMENTATION.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CHANGES.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TESTS.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ISSUES.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AGENT_REVIEW.md
‚îÇ   ‚îú‚îÄ‚îÄ fase-2/
‚îÇ   ‚îú‚îÄ‚îÄ fase-3/
‚îÇ   ‚îú‚îÄ‚îÄ fase-4/
‚îÇ   ‚îú‚îÄ‚îÄ fase-5/
‚îÇ   ‚îî‚îÄ‚îÄ fase-6/
‚îî‚îÄ‚îÄ snapshots/
    ‚îú‚îÄ‚îÄ database-agent.md (MODIFICAR - agregar pgvector)
    ‚îî‚îÄ‚îÄ infrastructure-monitor.md (MODIFICAR - remover Zilliz)
```

---

## üìù NOTAS IMPORTANTES

### Consideraciones T√©cnicas

1. **HNSW Index Performance**:
   - pgvector 0.8.0 usa HNSW (Hierarchical Navigable Small World)
   - Performance comparable a Milvus para < 1M vectors
   - Par√°metros: `m = 16` (conexiones), `ef_construction = 64` (calidad)
   - Trade-off: Mayor `m` = mejor recall, pero m√°s memoria

2. **Cosine Similarity**:
   - Operador: `<=>` (cosine distance)
   - Similarity = 1 - distance
   - Threshold: 0.7 (70% similarity m√≠nima)

3. **Batch Insert Optimization**:
   - BATCH_SIZE = 500 embeddings por insert
   - Evita timeout en inserts grandes
   - Progreso visible durante import

4. **Zero Downtime Strategy**:
   - Importar a pgvector ANTES de cambiar MCP config
   - Validar que b√∫squedas funcionan
   - LUEGO hacer switch de config
   - Rollback f√°cil (revertir config)

5. **Backup de Seguridad**:
   - Mantener export JSONL por 30 d√≠as post-migraci√≥n
   - Zilliz data disponible 30 d√≠as despu√©s de cancelar
   - Rollback posible si algo falla

6. **Embeddings NO se Re-generan**:
   - Usar embeddings existentes de Zilliz
   - NO re-indexar codebase (ahorra tiempo + costo OpenAI)
   - Solo si hay problemas de integridad

7. **Connection String Supabase**:
   - Usar **Pooler** (port 6543) para pgvector
   - NO usar port 5432 (direct connection tiene l√≠mites)
   - Format: `postgresql://postgres.[PROJECT_ID]:[PASSWORD]@aws-0-us-west-1.pooler.supabase.com:6543/postgres`

8. **MCP Server Compatibility**:
   - claude-context MCP debe soportar pgvector backend
   - Si no soporta, considerar fork o PR upstream
   - Alternativa: Crear custom MCP server para pgvector

---

**√öltima actualizaci√≥n:** 9 Octubre 2025
**Pr√≥ximo paso:** Crear TODO.md con tareas espec√≠ficas y luego zilliz-to-pgvector-prompt-workflow.md
